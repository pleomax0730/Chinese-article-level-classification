{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import process_dataset\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef52c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = \"../datasets/pondlet_gloss_HSK3_2021-all.csv;../datasets/pondlet_STB_HSK3_2021-all.csv\"\n",
    "datasets = \"../datasets/pondlet_STB_HSK3_20220708_percentage.csv\"\n",
    "balance_data = process_dataset(datasets)\n",
    "balance_data.drop(\"ID\", inplace=True, axis=1)\n",
    "balance_data.drop(balance_data[balance_data.Label == \"Lv.5\"].index, inplace=True, axis=0)\n",
    "balance_data.drop(balance_data[balance_data.Label == \"Lv.6\"].index, inplace=True, axis=0)\n",
    "balance_data.drop(balance_data[balance_data.Label == \"Lv.7-9\"].index, inplace=True, axis=0)\n",
    "\n",
    "# balance_data.drop(\"None\", inplace=True, axis=1)\n",
    "# balance_data.drop(\"7-9\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8ba7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d3ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_label = balance_data[\"Label\"].to_numpy()\n",
    "class_weights = compute_class_weight(\"balanced\", np.unique(np_label), np_label)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd3f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4745ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_data.Label.value_counts().plot.bar(rot=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6440b543",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = balance_data.iloc[:, 1:].to_numpy()\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(balance_data.Label)\n",
    "balance_data['categorical_label'] = le.transform(balance_data.Label)\n",
    "y = balance_data.iloc[:, -1].to_numpy()\n",
    "\n",
    "\n",
    "# ['Lv.1' 'Lv.2' 'Lv.3' 'Lv.4' 'Lv.5' 'Lv.6']\n",
    "print(le.classes_)\n",
    "\n",
    "\n",
    "X_tmp, X_test, y_tmp, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_tmp, y_tmp, test_size=0.1, stratify=y_tmp, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba7e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c8bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler.mean_, scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler.transform(X_tmp)\n",
    "# scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10d0672",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25facac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "le.inverse_transform([y_tmp[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece6ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "le.classes_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7e7ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 8)\n",
    "        self.layer2 = nn.Linear(8, 16)\n",
    "        self.layer3 = nn.Linear(16, 24)\n",
    "        self.layer4 = nn.Linear(24, 32)\n",
    "        self.layer5 = nn.Linear(32, 64)\n",
    "        self.layer6 = nn.Linear(64, 32)\n",
    "        self.layer7 = nn.Linear(32, 24)\n",
    "        self.layer8 = nn.Linear(24, 16)\n",
    "        self.layer9 = nn.Linear(16, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = F.relu(self.layer4(x))\n",
    "        x = F.relu(self.layer5(x))\n",
    "        x = F.relu(self.layer6(x))\n",
    "        x = F.relu(self.layer7(x))\n",
    "        x = F.relu(self.layer8(x))\n",
    "        return self.layer9(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eaba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):        \n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "test = CustomDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac3cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn   = nn.CrossEntropyLoss(weight=class_weights)\n",
    "loss_fn   = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258b6226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_dataloader, model, optimizer):\n",
    "\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        values, indices = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (indices == labels).sum().item()\n",
    "\n",
    "    acc = 100 * train_correct / train_total\n",
    "    loss = train_loss / len(train_dataloader)\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07392bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_one_epoch(val_dataloader, model):\n",
    "\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for data in val_dataloader:\n",
    "\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            values, indices = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (indices == labels).sum().item()\n",
    "\n",
    "    acc = 100 * val_correct / val_total\n",
    "    loss = val_loss / len(val_dataloader)\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb4f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_at_final(test_dataloader, model):\n",
    "\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    y_true, y_pred = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for data in test_dataloader:\n",
    "\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            values, indices = torch.max(outputs.data, 1)\n",
    "            # 忽略label是lv.6，預測不是lv.6的錯誤\n",
    "            # if labels.item() == 5 and indices.item() != 5:\n",
    "            #     continue\n",
    "\n",
    "            # # 忽略label不是lv.6，預測是lv.6的錯誤\n",
    "            # if labels.item() != 5 and indices.item() == 5:\n",
    "            #     continue\n",
    "\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (indices == labels).sum().item()\n",
    "            \n",
    "\n",
    "            y_true.extend(labels.tolist())\n",
    "            y_pred.extend(indices.tolist())\n",
    "\n",
    "    acc = 100 * test_correct / test_total\n",
    "    array = confusion_matrix(y_true, y_pred)\n",
    "    return acc, array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d6a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad41771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9603b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=4, random_state=seed, shuffle=True)\n",
    "kfold_train_acc = []\n",
    "kfold_val_acc = []\n",
    "kfold_test_acc = []\n",
    "cf_arrays = []\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(skf.split(X_tmp, y_tmp)):\n",
    "    X_train, X_val = X_tmp[train_index], X_tmp[val_index]\n",
    "    y_train, y_val = y_tmp[train_index], y_tmp[val_index]\n",
    "\n",
    "    X_train = torch.FloatTensor(X_train)\n",
    "    X_val = torch.FloatTensor(X_val)\n",
    "    y_train = torch.LongTensor(y_train)\n",
    "    y_val = torch.LongTensor(y_val)\n",
    "\n",
    "    train = CustomDataset(X_train, y_train)\n",
    "    val = CustomDataset(X_val, y_val)\n",
    "\n",
    "    train_dataloader = DataLoader(train, batch_size=8, shuffle=True)\n",
    "    val_dataloader = DataLoader(val, batch_size=8, shuffle=True)\n",
    "\n",
    "    model     = Model(X_train.shape[1], len(le.classes_))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "    train_acc_list = []\n",
    "    val_acc_list = []\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "\n",
    "    for _ in tqdm(range(3000)):\n",
    "        train_acc, train_loss = train_one_epoch(train_dataloader, model, optimizer)\n",
    "        train_acc_list.append(train_acc)\n",
    "        train_loss_list.append(train_loss)\n",
    "\n",
    "        val_acc, val_loss = val_one_epoch(val_dataloader, model)\n",
    "        val_acc_list.append(val_acc)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "    test_acc, cf_array = test_at_final(test_dataloader, model)\n",
    "    cf_arrays.append(cf_array)\n",
    "\n",
    "    kfold_train_acc.append(np.mean(train_acc_list))\n",
    "    kfold_val_acc.append(np.mean(val_acc_list))\n",
    "    kfold_test_acc.append(test_acc)\n",
    "    torch.save(model.state_dict(), f\"model_fold{i}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429aef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0b1d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6feddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, counts = np.unique(y_test, return_counts=True)\n",
    "for l, c in zip(labels, counts):\n",
    "    print(f\"Lable:{l}, Count:{c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5edcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Baseline acc:{100*counts.max()/counts.sum():.2f}\")\n",
    "print(f\"4 folds  acc:{np.mean(kfold_test_acc):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad931f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "for array in cf_arrays:\n",
    "    df_cm = pd.DataFrame(array, index = le.classes_.tolist(),\n",
    "                    columns = le.classes_.tolist())\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True, cmap=\"Blues_r\")\n",
    "    plt.xlabel('Pred')\n",
    "    plt.ylabel('True')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b9e6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb33e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "512607ff7c31323a1dd66289550dafca25ea34cbe421674c5f8c7944c3905019"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
